import os
import requests
from bs4 import BeautifulSoup
from supabase import create_client
import re
from datetime import datetime, timedelta, timezone

# --- 1. è¨­å®šã‚¨ãƒªã‚¢ ---
# GitHub Secretsã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
BASE_URL = "https://ikekari.com/attend.php"

# æ—¥æœ¬æ™‚é–“(JST)ã®è¨­å®š
JST = timezone(timedelta(hours=9))

# Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def scrape_and_sync():
    print(f"ğŸš€ ã‚·ãƒ•ãƒˆåŒæœŸã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹ã—ã¾ã—ãŸ (å®Ÿè¡Œæ™‚åˆ»: {datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')} JST)")
    
    # æœ¬æ—¥ã‹ã‚‰7æ—¥åˆ†ï¼ˆ1é€±é–“ï¼‰ã®ã‚·ãƒ•ãƒˆã‚’å·¡å›
    for i in range(7):
        target_date_obj = datetime.now(JST) + timedelta(days=i)
        target_date_str = target_date_obj.strftime("%Y/%m/%d") # URLç”¨
        db_date_str = target_date_obj.strftime("%Y-%m-%d")    # DBç™»éŒ²ç”¨
        
        url = f"{BASE_URL}?date_get={target_date_str}"
        print(f"--- {target_date_str} ã®æƒ…å ±ã‚’å–å¾—ä¸­ ---")
        
        try:
            response = requests.get(url, timeout=10)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å„ã‚­ãƒ£ã‚¹ãƒˆã®æƒ…å ±ã‚’æŠ½å‡º
            items = soup.find_all('li')
            
            for item in items:
                name_tag = item.find('h3')
                if not name_tag: continue
                
                # åå‰ã®ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼ˆã€Œåå‰ï¼ˆå¹´é½¢ï¼‰ã€â†’ã€Œåå‰ã€ï¼‰
                raw_name = name_tag.get_text()
                hp_name = re.sub(r'ï¼ˆ\d+ï¼‰', '', raw_name).strip()

                # å‡ºå‹¤æ™‚é–“ã®æŠ½å‡ºï¼ˆä¾‹: 20:00-05:00ï¼‰
                time_match = re.search(r'(\d{2}:\d{2})-(\d{2}:\d{2})', item.get_text())
                if not time_match: continue
                
                start_time = time_match.group(1)
                end_time = time_match.group(2)

                # Supabaseã®åç°¿(cast_members)ã‹ã‚‰IDã‚’æ¤œç´¢
                res = supabase.table("cast_members").select("login_id").eq("hp_display_name", hp_name).execute()
                
                if res.data:
                    login_id = res.data[0]['login_id']
                    
                    shift_data = {
                        "login_id": login_id,
                        "hp_display_name": hp_name,
                        "shift_date": db_date_str,
                        "start_time": start_time,
                        "end_time": end_time
                    }
                    
                    # ã€é‡è¦ã€‘on_conflict ã‚’æŒ‡å®šã—ã¦ã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°æ›´æ–°(Upsert)ã™ã‚‹
                    supabase.table("shifts").upsert(
                        shift_data, 
                        on_conflict="login_id,shift_date"
                    ).execute()
                    
                    print(f"  âœ… {hp_name} ({login_id}): {start_time} - {end_time}")
                else:
                    # åç°¿ã«ã„ãªã„ã‚­ãƒ£ã‚¹ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    pass
                    
        except Exception as e:
            print(f"  âŒ {target_date_str} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    scrape_and_sync()
