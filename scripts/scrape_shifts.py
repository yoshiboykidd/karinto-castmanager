import os
import requests
from bs4 import BeautifulSoup
from supabase import create_client
import re
from datetime import datetime, timedelta, timezone

# --- è¨­å®šã‚¨ãƒªã‚¢ ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
BASE_URL = "https://ikekari.com/attend.php"
JST = timezone(timedelta(hours=9)) # æ—¥æœ¬æ™‚é–“

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def scrape_and_sync():
    print(f"ğŸš€ åŒæœŸé–‹å§‹: {datetime.now(JST)}")
    
    for i in range(7):
        target_date_obj = datetime.now(JST) + timedelta(days=i)
        target_date_str = target_date_obj.strftime("%Y/%m/%d")
        db_date_str = target_date_obj.strftime("%Y-%m-%d")
        
        url = f"{BASE_URL}?date_get={target_date_str}"
        response = requests.get(url)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        for item in soup.find_all('li'):
            name_tag = item.find('h3')
            if not name_tag: continue
            
            hp_name = re.sub(r'ï¼ˆ\d+ï¼‰', '', name_tag.get_text()).strip()
            time_match = re.search(r'(\d{2}:\d{2})-(\d{2}:\d{2})', item.get_text())
            if not time_match: continue
            
            # 1. ã‚­ãƒ£ã‚¹ãƒˆåã‹ã‚‰ ID ã‚’å–å¾—
            res = supabase.table("cast_members").select("login_id").eq("hp_display_name", hp_name).execute()
            
            if res.data:
                login_id = res.data[0]['login_id']
                
                # 2. ã€é‡è¦ã€‘ç¾åœ¨ã®DBã®çŠ¶æ…‹ã‚’ç¢ºèª
                # ç”³è«‹ä¸­(requested)ã‹ã©ã†ã‹ã€ç¾åœ¨ã®ãƒ•ãƒ©ã‚°ã®çŠ¶æ…‹ã‚’å–å¾—ã—ã¾ã™
                existing_shift = supabase.table("shifts") \
                    .select("status, is_official") \
                    .eq("login_id", login_id) \
                    .eq("shift_date", db_date_str) \
                    .execute()

                # åŸºæœ¬ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆHPã«å­˜åœ¨ã™ã‚‹ã®ã§ pre_exist ã¯å¸¸ã« Trueï¼‰
                data = {
                    "login_id": login_id,
                    "hp_display_name": hp_name,
                    "shift_date": db_date_str,
                    "is_official_pre_exist": True  # å…¬å¼HPã«æ ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã®è¨¼æ˜
                }

                # 3. ä¸‰ã™ãã¿ãƒ­ã‚¸ãƒƒã‚¯ã«ã‚ˆã‚‹ä¸Šæ›¸ãåˆ¤å®š
                # ã™ã§ã«DBã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã€ã‹ã¤ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ 'requested'ï¼ˆç”³è«‹ä¸­ï¼‰ã®å ´åˆ
                if existing_shift.data and existing_shift.data[0].get('status') == 'requested':
                    print(f"  âš ï¸ {hp_name} ({db_date_str}) ã¯ç”³è«‹ä¸­ã®ãŸã‚ã€æ™‚é–“ã¯ä¸Šæ›¸ãã›ãš pre_exist ã®ã¿æ›´æ–°ã—ã¾ã™")
                    # data ã«ã¯ start_time, end_time, status, is_official ã‚’å«ã‚ãªã„ï¼ˆç¾åœ¨ã®ç”³è«‹å€¤ã‚’ä¿è­·ï¼‰
                else:
                    # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒ 'official' ã®å ´åˆã¯ã€HPã®å†…å®¹ã§æ›´æ–°
                    data.update({
                        "start_time": time_match.group(1),
                        "end_time": time_match.group(2),
                        "status": "official",
                        "is_official": True
                    })

                # 4. Upsert å®Ÿè¡Œ (on_conflict ã§ ID ã¨æ—¥ä»˜ãŒä¸€è‡´ã™ã‚‹è¡Œã‚’å¯¾è±¡ã«ã™ã‚‹)
                supabase.table("shifts").upsert(data, on_conflict="login_id,shift_date").execute()
                print(f"  âœ… {hp_name} ({db_date_str}) åŒæœŸå®Œäº†")

if __name__ == "__main__":
    scrape_and_sync()